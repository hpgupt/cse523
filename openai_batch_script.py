# -*- coding: utf-8 -*-
"""openai-batch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUt3nYIIcO0Swko-bMqsyI-qCZ0yrrEz
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import json
from openai import OpenAI

import getpass
import os
os.environ["OPENAI_API_KEY"] = getpass.getpass()

data_path = "/content/drive/MyDrive/ap_data/"

df = pd.read_csv(data_path+"twitter_data_1204.csv")

from langchain.prompts import ChatPromptTemplate
prompt_template = ChatPromptTemplate.from_template(
    """
    There are two pieces of information provided:
    This reply tweet left by a user on an another tweet: "{comment}"
    Identify whether the above reply tweet exhibits whataboutism. Let's think step by step. Please output your answer at the end as ##<answer>". The answer should be either of two options: "whataboutism" or "not whataboutism".
    """
)

client = OpenAI()

# def classify_comment(row):
#     prompt = prompt_template.format_messages(
#         title=row['Title'],
#         topic=row['Topic'],
#         comment=row['Comments']
#     )
#     print(prompt[0].content)
#     response = client.chat.completions.create(
#     model="gpt-4o",
#     temperature=0.3,
#     max_completion_tokens=500,
#     messages=[
#         {
#             "role": "user",
#             "content": prompt[0].content
#         }
#     ],
#     )
#     return response.choices[0].message

# Creating an array of json tasks
tasks = []
for index, row in df.iterrows():
    prompt = prompt_template.format_messages(
        title=row['Title'],
        topic=row['Topic'],
        comment=row['Comments']
    )

    task = {
        "custom_id": f"task-{index}",
        "method": "POST",
        "url": "/v1/chat/completions",
        "body": {
            "model": "gpt-4o",
            "temperature": 0.3,
            "max_tokens": 500,
            "messages": [
                {
                    "role": "user",
                    "content": prompt[0].content
                }
            ],
        }
    }
    tasks.append(task)

file_name = data_path+"4o-cot-0shot-notopic-tw.jsonl"

with open(file_name, 'w') as file:
    for obj in tasks:
        file.write(json.dumps(obj) + '\n')

"""Reading from output and results"""

def map_output(output):
    if '##whataboutism' in output:
        return 1
    elif '##not' in output:
        return 0
    elif 'not whataboutism' in output:
        return 0
    elif '##<answer>whataboutism' in output:
        return 1
    elif '##<answer>not' in output:
        return 0
    else:
        return None

file_path = '4o-cot-0shot-tw-out.jsonl'

proc = set()
res = []
with open(data_path+file_path, 'r', encoding='utf-8') as file:
  for line in file:
    result = json.loads(line.strip())
    if result['custom_id'] not in proc:
      proc.add(result['custom_id'])
      temp = map_output(result['response']['body']['choices'][0]['message']['content'])
      res.append(temp)

df['output'] = res

df.dropna(inplace=True,subset=['output'])

df.to_csv(data_path+"gpt4o-0shot-cot-tw.csv")

predicted_labels = list(df['output'])
actual_labels = list(df['Label'])

from sklearn.metrics import precision_score, recall_score, f1_score

def calculate_classwise_metrics(actual_labels, predicted_labels, class_name):
    precision = precision_score(actual_labels, predicted_labels, pos_label=class_name)
    recall = recall_score(actual_labels, predicted_labels, pos_label=class_name)
    f1 = f1_score(actual_labels, predicted_labels, pos_label=class_name)
    return precision, recall, f1

print("Dataset:")
classes = [0, 1]
for cls in classes:
    cl = "W" if cls else "NW"
    precision, recall, f1 = calculate_classwise_metrics(actual_labels, predicted_labels, class_name=cls)
    print(f"Class {cl} - Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}")